{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import AdamW, BertForSequenceClassification\n",
    "from tqdm import tqdm, trange\n",
    "import pandas as pd\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lucem_illud_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b7a2abf99143c391771cd800889ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=230, style=ProgressStyle(description_width=â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Allocate a pipeline for sentiment-analysis\n",
    "nlp_sentiment = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in overall dataframe\n",
    "movie_df = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in dataframes separated by year\n",
    "movie_df_1940_2020 = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df_1940_2020.csv\") \n",
    "movie_df_1940_1960 = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df_1940_1960.csv\")\n",
    "movie_df_1960_1980 = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df_1960_1980.csv\")\n",
    "movie_df_1980_2000 = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df_1980_2000.csv\")\n",
    "movie_df_2000_2020 = pd.read_csv(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/dataframes/movie_df_2000_2020.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "tokenizer_gpt = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "model_gpt = AutoModelWithLMHead.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing that we like to do more than analyse data all day long and then try to figure out what's going on.\n",
      "\n",
      "\"We're not going to be able to do that. We're not going to be able to do that.!\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Nothing that we like to do more than analyse data all day long and\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1940-1960 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text_1940_1960, test_text_1940_1960 = train_test_split(movie_df_1940_1960['Text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74    @@4423653 At 4 .. 00 a.m . on Friday , May 10 ...\n",
       "76    @@3611996 [?] How many times am I going to tel...\n",
       "59    @@6520352 Subtitles by Seglora How do you do M...\n",
       "0     @@6850720 You must do your best tonight Be on ...\n",
       "5     @@5089097 Extra ! Read all about it ! Again a ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_1940_1960.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_1940_1960.to_frame().to_csv(r'/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/train_text_1940_1960', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_1940_1960.to_frame().to_csv(r'/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/test_text_1940_1960', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_1940_1960 = AutoTokenizer.from_pretrained(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/output_gpt_1940_1960/\")\n",
    "model_1940_1960 = AutoModelWithLMHead.from_pretrained(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/output_gpt_1940_1960/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definition of violence is the act of violence against another person. It is the act of violence against another person. It is the act of violence against another person. It is the act of violence against another person. It is the act of violence\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The definition of violence is\"\n",
    "\n",
    "input = tokenizer_1940_1960.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_1940_1960.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_1940_1960.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.99191463}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"The definition of violence is the act of violence against another person.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definition of violence is not a matter of violence, but of violence that is not directed at the victim.\n",
      "\n",
      "The definition of violence is not a matter of violence, but of violence that is not directed at the victim. The definition of\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The definition of violence is\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9665815}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"The definition of violence is not a matter of violence, but of violence that is not directed at the victim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons are not allowed in the barracks. - I'll be back. - I'll be back. - I'll be back. - I'll be back. - I'll be back. - I'll be back. - I'll be back\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Weapons are\"\n",
    "\n",
    "input = tokenizer_1940_1960.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_1940_1960.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_1940_1960.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9893867}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"Weapons are not allowed in the barracks..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons are not available.\n",
      "\n",
      "The following weapons are not available.\n",
      "\n",
      "Weapon Name Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Weapons are\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.99960166}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"Weapons are not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2000-2020 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_text_2000_2020, test_text_2000_2020 = train_test_split(movie_df_2000_2020['Text'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414    @@6822898 ? ? ? [INAUDIBLE_DIALOGUE] One of my...\n",
       "312    @@6317249 A century ago , these fields were th...\n",
       "382    @@6127842 Ana , take my car . I gave you the r...\n",
       "237    @@3737502 RODRICK : ( WHISPERING ) Greg ? GREG...\n",
       "82     @@4239336 Spartacus ( 2004 ) - - 25 fps - - - ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_2000_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_2000_2020.to_frame().to_csv(r'/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/train_text_2000_2020', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_2000_2020.to_frame().to_csv(r'/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/test_text_2000_2020', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_2000_2020 = AutoTokenizer.from_pretrained(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/output_gpt_2000_2020/\")\n",
    "model_2000_2020 = AutoModelWithLMHead.from_pretrained(\"/Users/laurenbeard/Desktop/compContentAnalysis/Content-Analysis-2020/final/output/output_gpt_2000_2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definition of violence is that it's a violent act. It's a violent act. It's a violent act. It's a violent act. It's a violent act. It's a violent act. It's a violent act. It\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The definition of violence is\"\n",
    "\n",
    "input = tokenizer_2000_2020.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_2000_2020.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_2000_2020.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.99274975}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"The definition of violence is that it's a violent act.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The definition of violence is not a matter of violence, but of violence that is not directed at the victim.\n",
      "\n",
      "The definition of violence is not a matter of violence, but of violence that is not directed at the victim. The definition of\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"The definition of violence is\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9665815}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"The definition of violence is not a matter of violence, but of violence that is not directed at the victim.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons are not allowed. - You're not allowed to use them. - No. - No. - No. - No. - No. - No. - No. - No. - No. - No. - No. - No\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Weapons are\"\n",
    "\n",
    "input = tokenizer_2000_2020.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_2000_2020.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_2000_2020.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9979433}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"Weapons are not allowed. - You're not allowed to use them.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapons are not available.\n",
      "\n",
      "The following weapons are not available.\n",
      "\n",
      "Weapon Name Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type Damage Type\"\n"
     ]
    }
   ],
   "source": [
    "sequence = \"Weapons are\"\n",
    "\n",
    "input = tokenizer_gpt.encode(sequence, return_tensors=\"pt\")\n",
    "generated = model_gpt.generate(input, max_length=50, bos_token_id=1, pad_token_id=1, eos_token_ids=1)\n",
    "\n",
    "resulting_string = tokenizer_gpt.decode(generated.tolist()[0])\n",
    "print(resulting_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.99960166}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_sentiment(\"Weapons are not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
